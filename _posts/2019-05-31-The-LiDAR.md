---
layout:     post
title:      LiDAR is Genius's Errand
subtitle:   A Introduction To The LiDAR System
date:       2019-05-31
author:     Yaodong Cui
header-img: img/post-bg-incar.jpg
header-mask: 0.5
catalog: true
tags:
    - LiDAR
    - Point Cloud Processing
    - Perception
---


# What Is LiDAR and How LiDAR Work
LiDAR, which stands for Light Detection and Ranging, is a remote sensing method that uses light in the form of a pulsed laser to measure ranges (variable distances) to a object.  A LiDAR instrument principally consists of a laser, a scanner, and a specialized GPS receiver. 

<br>
<div  align="center"> 
    <img 
    src="https://raw.githubusercontent.com/yaodongC/yaodongC.github.io/master/post_img/190531/hesai40p2.PNG"
    width = "600" height = "300">
    <img 
    src="https://raw.githubusercontent.com/yaodongC/yaodongC.github.io/master/post_img/190531/hesai40p3.png"
    width = "600" height = "300"></div>
 <div align="center">Fig.1   The Hesai 40p LiDAR.</div>
<br> 

Most LiDARs for autonomous driving mount their laser emitters and receivers to a rotating motor to achieve a 360-degree view, with a typical refresh rate at 10Hz . The horizontal angular resolution of the LiDAR depends on the numbers of emitters and receivers it has. The vertical angular resolution depends on the installation angles of each emitter. 


# Autonomous Vehicle And LiDAR

LiDARs has been a part of the perception system on the autonomous vehicle since the early 90s. Most of the autonomous driving platforms today are equipped or even build around LiDARs. 
The LiDAR system enables the autonomous robot to acquire an accurate 3D representation of its surrounding environment, invariant to most of the lighting and weather conditions. The real challenges are to analyze and extract meaningful information, such as obstacles, their positions and velocity, from the 3D point cloud in real time. 

Compared to other types of sensors, LiDAR has the following advantages:
- Highly accurate depth information.
- Invariant to most of the lighting conditions.
- Decent resolution and range depending on your model.
- Invariant  to most weather conditions

However, it is not to say the LiDAR is a perfect sensor for autonomous driving. There are several severe disadvantages:
- Too expensive
- Cost too much
- Most of the time leads to an empty pocket
- Deep learning-based algorithms for point cloud processing is still under active research.
- New types of LiDAR for autonomous driving is under active development, which could be very different from LiDAR used today.
- Data size is huge.

One example of perception systems on autonomous car is shown in Fig.2. Waymo's most rencent autonomous vehicles are equipped with 5 LiDARs, which are all developed by Google.

<br>
<div  align="center"> 
    <img 
    src="https://raw.githubusercontent.com/yaodongC/yaodongC.github.io/master/post_img/190531/Waymo car-2.gif"
    width = "800" height = "450"></div>
 <div align="center">Fig.2   The Sensor Setup of Waymo Autonomouse Vehicle.</div>
<br>  

The high-resolution LiDAR on the top of the vehicle is fused with panoramic cameras. This enables fusion between images and point clouds, which can boost the texture detail that point cloud lacks.

The low-resolution LiDARs on the body of the vehicle is fused with radar.  This allows accurate speed measuring of objects, which can be projected to point clouds.

# Point Cloud

Point cloud isn't the ideal data structure that you want to work with. There are several challenges that one might face when processing the LiDAR  point cloud.



<br>
<div  align="center"> 
    <img 
    src="https://raw.githubusercontent.com/yaodongC/yaodongC.github.io/master/post_img/190531/行驶.gif"
    width = "500" height = "280"></div>
 <div align="center">Fig.2   Point Cloud of a street,Looking through LiDAR's eye.</div>
<br>  

<br>
<div  align="center"> 
    <img 
    src="https://raw.githubusercontent.com/yaodongC/yaodongC.github.io/master/post_img/190531/路口.gif"
    width = "500" height = "280"></div>
 <div align="center">Fig.3    Point Cloud of a cross,Looking through LiDAR's eye.</div>
<br>  



# Segmentation 
## Traditional paradigm
Current approaches for point cloud segmentation, comprise or use parts of the following stages: Remove the ground, cluster the remaining points into instances, extract (handcrafted) features from each cluster, classify and label each cluster based on its features, match objects between frames based on their features. 



# Tracking and Speed Estimation



# Conclusion

# References

- [1] Dominic Zeng Wang, I. Posner, and P. Newman. What could move? ﬁnding cars, pedestrians and bicyclists in 3d laser data. In 2012 IEEE International Conference on Robotics and Automation, pages 4038–4044, May 2012. 
- [2] B.Douillard, J.Underwood, N.Kuntz, V.Vlaskine, A.Quadros, P.Morton, andA.Frenkel. On the segmentation of 3d lidar point clouds. In 2011 IEEE International Conference on Robotics and Automation, pages 2798–2805, May 2011. 
- [3] Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR), 2012. 
- [4] Paul Voigtlaender, Michael Krause, Aljosa Osep, Jonathon Luiten, Berin Balachandar Gnana Sekar, Andreas Geiger, and Bastian Leibe. Mots: Multi-object tracking and segmentation. In Conference on Computer Vision and Pattern Recognition (CVPR), 2019. 
- [5] Bichen Wu, Alvin Wan, Xiangyu Yue, and Kurt Keutzer. Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud. 2018 IEEE International Conference on Robotics and Automation (ICRA), May 2018. 
- [6] D.Zermas,I.Izzat,andN.Papanikolopoulos. Fastsegmentationof3dpointclouds: Aparadigm on lidar data for autonomous vehicle applications. In 2017 IEEE International Conference on Robotics and Automation (ICRA), pages 5067–5073, May 2017.
